{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reasoning for Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we’ll explore how to use the o1 model, specifically the o1-preview, to perform data validation through reasoning. We’ll walk through a practical example involving a synthetic medical dataset and demonstrate how to assess the model’s accuracy in identifying issues within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Data validation is a critical step in ensuring the quality and reliability of datasets, especially in sensitive fields like healthcare. Traditional validation methods often rely on predefined rules and patterns. However, advanced  models like o1 can understand context and reason about data, offering a more flexible and intelligent approach to validation.\n",
    "\n",
    "In this tutorial, we’ll:\n",
    "    - Generate a synthetic dataset of medical data that contains inconsistencies.\n",
    "\t- Define a function that takes in a row of data and validates its accuracy\n",
    "\t- Run the validation process and compute evaluation metrics.\n",
    "\t- Analyze and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "MODEL = 'o1-preview'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a lot of the principles described in the [Synthetic Data Generation](https://cookbook.openai.com/examples/sdg1) cookbook to create the foundation of our dataset.\n",
    "\n",
    "We will prompt the model to generate sets of medical data for our use case. We have prompted the model to intentionally create inaccuracies in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "                You are a helpful assistant designed to generate data. The user will give you a format for the data to generate and some examples of the data.\n",
    "\n",
    "                When generating Patient IDs, use the format 'P' followed by a three-digit number (e.g., P006, P941, P319).\n",
    "\n",
    "                Intentionally make some mistakes in the data generation and document them in the appropriate columns ('Is Valid' and 'Issue') if the row of data is invalid.\n",
    "\n",
    "                The types of mistakes to include are:\n",
    "\n",
    "                - **Allergy Contradictions**: Prescribing a medication that the patient is allergic to (e.g., prescribing Penicillin to a patient allergic to Penicillin).\n",
    "                - **Medical History and Medication Mismatch**: A patient with a medical condition not receiving appropriate medication (e.g., a diabetic patient not prescribed any diabetes medication).\n",
    "                - **Lab Results and Diagnosis Mismatch**: Lab results that do not support the diagnosis (e.g., normal glucose levels but diagnosed with Diabetes Type 2).\n",
    "                - **Other Plausible Mistakes**: Any other realistic errors that could occur in medical records, such as incorrect gender entries, impossible dates of birth, or inconsistent treatment plans.\n",
    "\n",
    "                Ensure that when 'Is Valid' is 'False', the 'Issue' column clearly explains the problem.\n",
    "\n",
    "                Return 100 rows of data for the user.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "                Generate Synthetic Medical Records Dataset with the following columns:\n",
    "                    - Patient ID: A randomly generated patient id\n",
    "                    - Date of Birth: Date of birth of the patient\n",
    "                    - Gender: M/F\n",
    "                    - Medical History: Past diagnoses\n",
    "                    - Current Medications: Medication the patient is taking\n",
    "                    - Allergies: Identified allergies\n",
    "                    - Lab Results (Glucose mg/dL)\n",
    "                    - Diagnoses: Current diagnosis\n",
    "                    - Treatment Plan: Current treatment plan\n",
    "                    - Is Valid: Whether or not the current row of data is valid (True/False)\n",
    "                    - Issue: If the row of data is not valid, what the issue is\n",
    "\n",
    "                Patient ID,Date of Birth,Gender,Medical History,Current Medications,Allergies,Lab Results (Glucose mg/dL),Diagnoses,Treatment Plan,Is Valid,Issue\n",
    "                P001,1980-05-14,M,Hypertension,Lisinopril,None,110,Hypertension,Continue Lisinopril,True,\n",
    "                P002,1975-11-30,F,Diabetes Type 2,Metformin,Penicillin,90,Diabetes Type 2,Continue Metformin,True,\n",
    "                P003,1990-07-22,F,Asthma,Albuterol,Aspirin,85,Asthma,Prescribe Albuterol,True,\n",
    "                P004,2000-03-10,M,None,Amoxicillin,Penicillin,95,Infection,Prescribe Amoxicillin,False,Prescribed Amoxicillin despite Penicillin allergy\n",
    "                P005,1985-09-18,F,Hyperlipidemia,Atorvastatin,None,200,Hyperlipidemia,Continue Atorvastatin,True,\n",
    "                P006,1978-12-05,M,Hypertension; Diabetes Type 2,Lisinopril; Insulin,None,55,Diabetes Type 2,Adjust insulin dosage,False,Low glucose level not properly addressed\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.replace('```csv', '').replace('```', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data generation and appending completed.\n"
     ]
    }
   ],
   "source": [
    "# Generate data three times using the existing dataGeneration function\n",
    "generated_data = []\n",
    "data = data_generation()\n",
    "generated_data.extend(data.strip().split('\\n'))\n",
    "\n",
    "# Append the generated data to the medicalData.csv file\n",
    "with open('medicalData.csv', 'a', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for row in generated_data:\n",
    "        csvwriter.writerow(row.split(','))\n",
    "\n",
    "print(\"Synthetic data generation and appending completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset prepared, we will prompt the reasoning model to review each row of data and determine whether or not it contains an issue. We will ask the model to output whether or not there is an issue in the data and then offer an explanation of the issue.\n",
    "\n",
    "Once we have the model determine its list of invalid data, we will pass those results on to a model grader to assess two metrics:\n",
    "- Accuracy of the model's ability correctly identify issues with the data\n",
    "- For the subset of data that issues have been correctly identified, what is the accuracy of the model in identifying the issue at hand\n",
    "\n",
    "Given that this task is much more narrow, we can use the faster gpt-4o model to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_validation(input_data):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "                You are a helpful assistant designed to validate the quality of medical datasets. You will be given a single row of medical data, and your task is to determine whether the data is valid.\n",
    "\n",
    "                - Carefully analyze the data for any inconsistencies, contradictions, missing values, or implausible information.\n",
    "                - Consider the logical relationships between different fields (e.g., treatments should be appropriate for the diagnoses, medications should not conflict with allergies, lab results should be consistent with diagnoses, etc.).\n",
    "                - Use your general medical knowledge and common sense to assess the validity of the data.\n",
    "                - Focus solely on the information provided without making assumptions beyond the given data.\n",
    "\n",
    "                **Return only a JSON object** with the following two properties:\n",
    "\n",
    "                - `\"reasoning\"`: this is a string property for you to write down all of your thoughts. Use this property to write down any thinking while reviewing the data.\n",
    "                - `\"is_valid\"`: a boolean (`true` or `false`) indicating whether the data is valid.\n",
    "                - `\"issue\"`: if `\"is_valid\"` is `false`, provide a brief explanation of the issue; if `\"is_valid\"` is `true`, set `\"issue\"` to `null`.\n",
    "\n",
    "                Both JSON properties must always be present.\n",
    "\n",
    "                Do not include any additional text or explanations outside the JSON object.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"{input_data}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content.replace('```json', '').replace('```', '').strip()\n",
    "    \n",
    "    try:\n",
    "        if isinstance(response_content, dict):\n",
    "            response_dict = response_content\n",
    "        else:\n",
    "            response_dict = json.loads(response_content)\n",
    "        return response_dict\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to decode JSON response: {response_content}\")\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file and exclude the last two columns\n",
    "input_data = []\n",
    "with open('medicalData.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = next(reader)\n",
    "    for row in reader:\n",
    "        input_data.append(row[:-2])  # Exclude \"Is Valid\" and \"Issue\" columns\n",
    "\n",
    "# Initialize lists to store true labels\n",
    "true_is_valid = []\n",
    "true_issues = []\n",
    "\n",
    "# Extract true labels from the CSV file\n",
    "with open('medicalData.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = next(reader)\n",
    "    for row in reader:\n",
    "        true_is_valid.append(row[-2] == 'True')\n",
    "        true_issues.append(row[-1])\n",
    "\n",
    "# Function to validate a single row of data\n",
    "def validate_row(row):\n",
    "    input_str = ','.join(row)\n",
    "    result_json = data_validation(input_str)\n",
    "    return result_json\n",
    "\n",
    "# Validate data rows and collect results\n",
    "pred_is_valid = [False] * len(input_data)\n",
    "pred_issues = [''] * len(input_data)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(validate_row, row): i for i, row in enumerate(input_data)}\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        i = futures[future]  # Get the index of the current row\n",
    "        result_json = future.result()\n",
    "        pred_is_valid[i] = result_json['is_valid']\n",
    "        pred_issues[i] = result_json['issue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model's results, we can compare it against the source of truth and determine the system's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted and true 'is_valid' labels to boolean if they aren't already\n",
    "pred_is_valid_bool = [bool(val) if isinstance(val, bool) else val == 'True' for val in pred_is_valid]\n",
    "true_is_valid_bool = [bool(val) if isinstance(val, bool) else val == 'True' for val in true_is_valid]\n",
    "\n",
    "# Calculate precision, recall, and f1 score for the 'is_valid' prediction\n",
    "precision = precision_score(true_is_valid_bool, pred_is_valid_bool, pos_label=True)\n",
    "recall = recall_score(true_is_valid_bool, pred_is_valid_bool, pos_label=True)\n",
    "f1 = f1_score(true_is_valid_bool, pred_is_valid_bool, pos_label=True)\n",
    "\n",
    "# Initialize issue_matches_full with False\n",
    "issue_matches_full = [False] * len(true_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7647058823529411\n",
      "Recall: 0.8253968253968254\n",
      "F1: 0.7938931297709924\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now determine the model's ability to accurately classify the issue in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_issue(model_generated_answer, correct_answer):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "                You are a helpful assistant designed to validate the quality of an LLM generated answer.\n",
    "\n",
    "                The model was asked to review a row of data in a medical dataset and determine if the data is valid. If the data was not valid, it was required to provide justification for why it is not valid.\n",
    "\n",
    "                The user will provide you with the model generated justification for an invalid row of data. Your task is to compare it to the correct reason and determine if they are the same justification.\n",
    "\n",
    "                If they are the same, return True. If they are different, return False. The do not have to be the same in exact wording, but rather the same meaning. Only respond with a single True/False.\n",
    "\n",
    "                Example 1:\n",
    "                    - Model Generated Response: The patient is allergic to penecillin\n",
    "                    - Correct Response: The patient was prescribed penecillin despite being allergic\n",
    "                    - Answer: True\n",
    "\n",
    "                Example 2:\n",
    "                    - Model Generated Response: The date of birth of the patient is incorrect\n",
    "                    - Correct Response: The patient was prescribed penecillin despite being allergic\n",
    "                    - Answer: False\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                Model Generated Response: {model_generated_answer}\n",
    "                Correct Response:  {correct_answer}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate issues for rows where both true and predicted 'is_valid' are False\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {\n",
    "        executor.submit(validate_issue, pred_issues[i], true_issues[i]): i\n",
    "        for i in range(len(pred_is_valid_bool))\n",
    "        if not pred_is_valid_bool[i] and not true_is_valid_bool[i]\n",
    "    }\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        i = futures[future]  # Get the original index\n",
    "        issue_match = future.result()\n",
    "        issue_matches_full[i] = (issue_match == 'True')\n",
    "    \n",
    "    # Create true labels for issue validation (True where there is an issue)\n",
    "    true_issue_labels = [not val for val in true_is_valid_bool]\n",
    "    \n",
    "    # Calculate precision, recall, and f1 score for issue identification\n",
    "    issue_precision = precision_score(true_issue_labels, issue_matches_full, pos_label=True)\n",
    "    issue_recall = recall_score(true_issue_labels, issue_matches_full, pos_label=True)\n",
    "    issue_f1 = f1_score(true_issue_labels, issue_matches_full, pos_label=True)\n",
    "    \n",
    "    # Store the results in the dictionary\n",
    "    model_results = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"issue_precision\": issue_precision,\n",
    "        \"issue_recall\": issue_recall,\n",
    "        \"issue_f1\": issue_f1\n",
    "    }\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "df_results = pd.DataFrame([model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision    recall        f1  issue_precision  issue_recall  issue_f1\n",
      "0   0.764706  0.825397  0.793893              1.0      0.216216  0.355556\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
